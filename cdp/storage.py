# # DO NOT EDIT THIS FILE!
# #
# # This file is generated from the CDP specification using AST. If you need to make
# # changes, edit the generator and regenerate all of the modules.

from __future__ import annotations
"""CDP domain: Storage (experimental)"""
import typing
import enum
from dataclasses import dataclass
from .util import T_JSON_DICT, event_class
from . import browser
from . import network
from . import page
None


@dataclass
class AttributionReportingAggregatableDebugReportingConfig:
    key_piece: UnsignedInt128AsBase16
    debug_data: typing.List[AttributionReportingAggregatableDebugReportingData]
    budget: typing.Optional[float] = None
    aggregation_coordinator_origin: typing.Optional[str] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['keyPiece'] = self.key_piece.to_json()
        json_data['debugData'] = [i.to_json() for i in self.debug_data]
        if self.budget is not None:
            json_data['budget'] = self.budget
        if self.aggregation_coordinator_origin is not None:
            json_data['aggregationCoordinatorOrigin'
                ] = self.aggregation_coordinator_origin
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingAggregatableDebugReportingConfig:
        return cls(key_piece=UnsignedInt128AsBase16.from_json(json_obj[
            'keyPiece']), debug_data=[
            AttributionReportingAggregatableDebugReportingData.from_json(i) for
            i in json_obj['debugData']], budget=json_obj['budget'] if 
            json_obj.get('budget') is not None else None,
            aggregation_coordinator_origin=json_obj[
            'aggregationCoordinatorOrigin'] if json_obj.get(
            'aggregationCoordinatorOrigin') is not None else None)


@dataclass
class AttributionReportingAggregatableDebugReportingData:
    key_piece: UnsignedInt128AsBase16
    value: float
    types: typing.List[str]

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['keyPiece'] = self.key_piece.to_json()
        json_data['value'] = self.value
        json_data['types'] = [i for i in self.types]
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingAggregatableDebugReportingData:
        return cls(key_piece=UnsignedInt128AsBase16.from_json(json_obj[
            'keyPiece']), value=json_obj['value'], types=[i for i in
            json_obj['types']])


@dataclass
class AttributionReportingAggregatableDedupKey:
    filters: AttributionReportingFilterPair
    dedup_key: typing.Optional[UnsignedInt64AsBase10] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['filters'] = self.filters.to_json()
        if self.dedup_key is not None:
            json_data['dedupKey'] = self.dedup_key.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingAggregatableDedupKey:
        return cls(filters=AttributionReportingFilterPair.from_json(
            json_obj['filters']), dedup_key=UnsignedInt64AsBase10.from_json
            (json_obj['dedupKey']) if json_obj.get('dedupKey') is not None else
            None)


@dataclass
class AttributionReportingAggregatableTriggerData:
    key_piece: UnsignedInt128AsBase16
    source_keys: typing.List[str]
    filters: AttributionReportingFilterPair

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['keyPiece'] = self.key_piece.to_json()
        json_data['sourceKeys'] = [i for i in self.source_keys]
        json_data['filters'] = self.filters.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingAggregatableTriggerData:
        return cls(key_piece=UnsignedInt128AsBase16.from_json(json_obj[
            'keyPiece']), source_keys=[i for i in json_obj['sourceKeys']],
            filters=AttributionReportingFilterPair.from_json(json_obj[
            'filters']))


@dataclass
class AttributionReportingAggregatableValueDictEntry:
    key: str
    value: float
    filtering_id: UnsignedInt64AsBase10

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['key'] = self.key
        json_data['value'] = self.value
        json_data['filteringId'] = self.filtering_id.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingAggregatableValueDictEntry:
        return cls(key=json_obj['key'], value=json_obj['value'],
            filtering_id=UnsignedInt64AsBase10.from_json(json_obj[
            'filteringId']))


@dataclass
class AttributionReportingAggregatableValueEntry:
    values: typing.List[AttributionReportingAggregatableValueDictEntry]
    filters: AttributionReportingFilterPair

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['values'] = [i.to_json() for i in self.values]
        json_data['filters'] = self.filters.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingAggregatableValueEntry:
        return cls(values=[AttributionReportingAggregatableValueDictEntry.
            from_json(i) for i in json_obj['values']], filters=
            AttributionReportingFilterPair.from_json(json_obj['filters']))


@dataclass
class AttributionReportingAggregationKeysEntry:
    key: str
    value: UnsignedInt128AsBase16

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['key'] = self.key
        json_data['value'] = self.value.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingAggregationKeysEntry:
        return cls(key=json_obj['key'], value=UnsignedInt128AsBase16.
            from_json(json_obj['value']))


@dataclass
class AttributionReportingEventReportWindows:
    start: int
    ends: typing.List[int]

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['start'] = self.start
        json_data['ends'] = [i for i in self.ends]
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingEventReportWindows:
        return cls(start=json_obj['start'], ends=[i for i in json_obj['ends']])


@dataclass
class AttributionReportingEventTriggerData:
    data: UnsignedInt64AsBase10
    priority: SignedInt64AsBase10
    filters: AttributionReportingFilterPair
    dedup_key: typing.Optional[UnsignedInt64AsBase10] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['data'] = self.data.to_json()
        json_data['priority'] = self.priority.to_json()
        json_data['filters'] = self.filters.to_json()
        if self.dedup_key is not None:
            json_data['dedupKey'] = self.dedup_key.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingEventTriggerData:
        return cls(data=UnsignedInt64AsBase10.from_json(json_obj['data']),
            priority=SignedInt64AsBase10.from_json(json_obj['priority']),
            filters=AttributionReportingFilterPair.from_json(json_obj[
            'filters']), dedup_key=UnsignedInt64AsBase10.from_json(json_obj
            ['dedupKey']) if json_obj.get('dedupKey') is not None else None)


@dataclass
class AttributionReportingFilterConfig:
    filter_values: typing.List[AttributionReportingFilterDataEntry]
    lookback_window: typing.Optional[int] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['filterValues'] = [i.to_json() for i in self.filter_values]
        if self.lookback_window is not None:
            json_data['lookbackWindow'] = self.lookback_window
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingFilterConfig:
        return cls(filter_values=[AttributionReportingFilterDataEntry.
            from_json(i) for i in json_obj['filterValues']],
            lookback_window=json_obj['lookbackWindow'] if json_obj.get(
            'lookbackWindow') is not None else None)


@dataclass
class AttributionReportingFilterDataEntry:
    key: str
    values: typing.List[str]

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['key'] = self.key
        json_data['values'] = [i for i in self.values]
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingFilterDataEntry:
        return cls(key=json_obj['key'], values=[i for i in json_obj['values']])


@dataclass
class AttributionReportingFilterPair:
    filters: typing.List[AttributionReportingFilterConfig]
    not_filters: typing.List[AttributionReportingFilterConfig]

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['filters'] = [i.to_json() for i in self.filters]
        json_data['notFilters'] = [i.to_json() for i in self.not_filters]
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->AttributionReportingFilterPair:
        return cls(filters=[AttributionReportingFilterConfig.from_json(i) for
            i in json_obj['filters']], not_filters=[
            AttributionReportingFilterConfig.from_json(i) for i in json_obj
            ['notFilters']])


@dataclass
class AttributionReportingSourceRegistration:
    time: network.TimeSinceEpoch
    expiry: int
    trigger_specs: typing.List[AttributionReportingTriggerSpec]
    aggregatable_report_window: int
    type_: AttributionReportingSourceType
    source_origin: str
    reporting_origin: str
    destination_sites: typing.List[str]
    event_id: UnsignedInt64AsBase10
    priority: SignedInt64AsBase10
    filter_data: typing.List[AttributionReportingFilterDataEntry]
    aggregation_keys: typing.List[AttributionReportingAggregationKeysEntry]
    trigger_data_matching: AttributionReportingTriggerDataMatching
    destination_limit_priority: SignedInt64AsBase10
    aggregatable_debug_reporting_config: AttributionReportingAggregatableDebugReportingConfig
    max_event_level_reports: int
    debug_key: typing.Optional[UnsignedInt64AsBase10] = None
    scopes_data: typing.Optional[AttributionScopesData] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['time'] = self.time.to_json()
        json_data['expiry'] = self.expiry
        json_data['triggerSpecs'] = [i.to_json() for i in self.trigger_specs]
        json_data['aggregatableReportWindow'] = self.aggregatable_report_window
        json_data['type'] = self.type_.to_json()
        json_data['sourceOrigin'] = self.source_origin
        json_data['reportingOrigin'] = self.reporting_origin
        json_data['destinationSites'] = [i for i in self.destination_sites]
        json_data['eventId'] = self.event_id.to_json()
        json_data['priority'] = self.priority.to_json()
        json_data['filterData'] = [i.to_json() for i in self.filter_data]
        json_data['aggregationKeys'] = [i.to_json() for i in self.
            aggregation_keys]
        json_data['triggerDataMatching'] = self.trigger_data_matching.to_json()
        json_data['destinationLimitPriority'
            ] = self.destination_limit_priority.to_json()
        json_data['aggregatableDebugReportingConfig'
            ] = self.aggregatable_debug_reporting_config.to_json()
        json_data['maxEventLevelReports'] = self.max_event_level_reports
        if self.debug_key is not None:
            json_data['debugKey'] = self.debug_key.to_json()
        if self.scopes_data is not None:
            json_data['scopesData'] = self.scopes_data.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingSourceRegistration:
        return cls(time=network.TimeSinceEpoch.from_json(json_obj['time']),
            expiry=json_obj['expiry'], trigger_specs=[
            AttributionReportingTriggerSpec.from_json(i) for i in json_obj[
            'triggerSpecs']], aggregatable_report_window=json_obj[
            'aggregatableReportWindow'], type_=
            AttributionReportingSourceType.from_json(json_obj['type']),
            source_origin=json_obj['sourceOrigin'], reporting_origin=
            json_obj['reportingOrigin'], destination_sites=[i for i in
            json_obj['destinationSites']], event_id=UnsignedInt64AsBase10.
            from_json(json_obj['eventId']), priority=SignedInt64AsBase10.
            from_json(json_obj['priority']), filter_data=[
            AttributionReportingFilterDataEntry.from_json(i) for i in
            json_obj['filterData']], aggregation_keys=[
            AttributionReportingAggregationKeysEntry.from_json(i) for i in
            json_obj['aggregationKeys']], trigger_data_matching=
            AttributionReportingTriggerDataMatching.from_json(json_obj[
            'triggerDataMatching']), destination_limit_priority=
            SignedInt64AsBase10.from_json(json_obj[
            'destinationLimitPriority']),
            aggregatable_debug_reporting_config=
            AttributionReportingAggregatableDebugReportingConfig.from_json(
            json_obj['aggregatableDebugReportingConfig']),
            max_event_level_reports=json_obj['maxEventLevelReports'],
            debug_key=UnsignedInt64AsBase10.from_json(json_obj['debugKey']) if
            json_obj.get('debugKey') is not None else None, scopes_data=
            AttributionScopesData.from_json(json_obj['scopesData']) if 
            json_obj.get('scopesData') is not None else None)


@dataclass
class AttributionReportingTriggerRegistration:
    filters: AttributionReportingFilterPair
    aggregatable_dedup_keys: typing.List[
        AttributionReportingAggregatableDedupKey]
    event_trigger_data: typing.List[AttributionReportingEventTriggerData]
    aggregatable_trigger_data: typing.List[
        AttributionReportingAggregatableTriggerData]
    aggregatable_values: typing.List[AttributionReportingAggregatableValueEntry
        ]
    aggregatable_filtering_id_max_bytes: int
    debug_reporting: bool
    source_registration_time_config: AttributionReportingSourceRegistrationTimeConfig
    aggregatable_debug_reporting_config: AttributionReportingAggregatableDebugReportingConfig
    scopes: typing.List[str]
    debug_key: typing.Optional[UnsignedInt64AsBase10] = None
    aggregation_coordinator_origin: typing.Optional[str] = None
    trigger_context_id: typing.Optional[str] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['filters'] = self.filters.to_json()
        json_data['aggregatableDedupKeys'] = [i.to_json() for i in self.
            aggregatable_dedup_keys]
        json_data['eventTriggerData'] = [i.to_json() for i in self.
            event_trigger_data]
        json_data['aggregatableTriggerData'] = [i.to_json() for i in self.
            aggregatable_trigger_data]
        json_data['aggregatableValues'] = [i.to_json() for i in self.
            aggregatable_values]
        json_data['aggregatableFilteringIdMaxBytes'
            ] = self.aggregatable_filtering_id_max_bytes
        json_data['debugReporting'] = self.debug_reporting
        json_data['sourceRegistrationTimeConfig'
            ] = self.source_registration_time_config.to_json()
        json_data['aggregatableDebugReportingConfig'
            ] = self.aggregatable_debug_reporting_config.to_json()
        json_data['scopes'] = [i for i in self.scopes]
        if self.debug_key is not None:
            json_data['debugKey'] = self.debug_key.to_json()
        if self.aggregation_coordinator_origin is not None:
            json_data['aggregationCoordinatorOrigin'
                ] = self.aggregation_coordinator_origin
        if self.trigger_context_id is not None:
            json_data['triggerContextId'] = self.trigger_context_id
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingTriggerRegistration:
        return cls(filters=AttributionReportingFilterPair.from_json(
            json_obj['filters']), aggregatable_dedup_keys=[
            AttributionReportingAggregatableDedupKey.from_json(i) for i in
            json_obj['aggregatableDedupKeys']], event_trigger_data=[
            AttributionReportingEventTriggerData.from_json(i) for i in
            json_obj['eventTriggerData']], aggregatable_trigger_data=[
            AttributionReportingAggregatableTriggerData.from_json(i) for i in
            json_obj['aggregatableTriggerData']], aggregatable_values=[
            AttributionReportingAggregatableValueEntry.from_json(i) for i in
            json_obj['aggregatableValues']],
            aggregatable_filtering_id_max_bytes=json_obj[
            'aggregatableFilteringIdMaxBytes'], debug_reporting=json_obj[
            'debugReporting'], source_registration_time_config=
            AttributionReportingSourceRegistrationTimeConfig.from_json(
            json_obj['sourceRegistrationTimeConfig']),
            aggregatable_debug_reporting_config=
            AttributionReportingAggregatableDebugReportingConfig.from_json(
            json_obj['aggregatableDebugReportingConfig']), scopes=[i for i in
            json_obj['scopes']], debug_key=UnsignedInt64AsBase10.from_json(
            json_obj['debugKey']) if json_obj.get('debugKey') is not None else
            None, aggregation_coordinator_origin=json_obj[
            'aggregationCoordinatorOrigin'] if json_obj.get(
            'aggregationCoordinatorOrigin') is not None else None,
            trigger_context_id=json_obj['triggerContextId'] if json_obj.get
            ('triggerContextId') is not None else None)


@dataclass
class AttributionReportingTriggerSpec:
    trigger_data: typing.List[float]
    event_report_windows: AttributionReportingEventReportWindows

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['triggerData'] = [i for i in self.trigger_data]
        json_data['eventReportWindows'] = self.event_report_windows.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingTriggerSpec:
        return cls(trigger_data=[i for i in json_obj['triggerData']],
            event_report_windows=AttributionReportingEventReportWindows.
            from_json(json_obj['eventReportWindows']))


@dataclass
class AttributionScopesData:
    values: typing.List[str]
    limit: float
    max_event_states: float

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['values'] = [i for i in self.values]
        json_data['limit'] = self.limit
        json_data['maxEventStates'] = self.max_event_states
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->AttributionScopesData:
        return cls(values=[i for i in json_obj['values']], limit=json_obj[
            'limit'], max_event_states=json_obj['maxEventStates'])


@dataclass
class RelatedWebsiteSet:
    """A single Related Website Set object."""
    primary_sites: typing.List[str]
    associated_sites: typing.List[str]
    service_sites: typing.List[str]

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['primarySites'] = [i for i in self.primary_sites]
        json_data['associatedSites'] = [i for i in self.associated_sites]
        json_data['serviceSites'] = [i for i in self.service_sites]
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->RelatedWebsiteSet:
        return cls(primary_sites=[i for i in json_obj['primarySites']],
            associated_sites=[i for i in json_obj['associatedSites']],
            service_sites=[i for i in json_obj['serviceSites']])


@dataclass
class SharedStorageAccessParams:
    """Bundles the parameters for shared storage access events whose
presence/absence can vary according to SharedStorageAccessType."""
    script_source_url: typing.Optional[str] = None
    operation_name: typing.Optional[str] = None
    serialized_data: typing.Optional[str] = None
    urls_with_metadata: typing.Optional[typing.List[
        SharedStorageUrlWithMetadata]] = None
    key: typing.Optional[str] = None
    value: typing.Optional[str] = None
    ignore_if_present: typing.Optional[bool] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        if self.script_source_url is not None:
            json_data['scriptSourceUrl'] = self.script_source_url
        if self.operation_name is not None:
            json_data['operationName'] = self.operation_name
        if self.serialized_data is not None:
            json_data['serializedData'] = self.serialized_data
        if self.urls_with_metadata is not None:
            json_data['urlsWithMetadata'] = [i.to_json() for i in self.
                urls_with_metadata]
        if self.key is not None:
            json_data['key'] = self.key
        if self.value is not None:
            json_data['value'] = self.value
        if self.ignore_if_present is not None:
            json_data['ignoreIfPresent'] = self.ignore_if_present
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->SharedStorageAccessParams:
        return cls(script_source_url=json_obj['scriptSourceUrl'] if 
            json_obj.get('scriptSourceUrl') is not None else None,
            operation_name=json_obj['operationName'] if json_obj.get(
            'operationName') is not None else None, serialized_data=
            json_obj['serializedData'] if json_obj.get('serializedData') is not
            None else None, urls_with_metadata=[
            SharedStorageUrlWithMetadata.from_json(i) for i in json_obj[
            'urlsWithMetadata']] if json_obj.get('urlsWithMetadata') is not
            None else None, key=json_obj['key'] if json_obj.get('key') is not
            None else None, value=json_obj['value'] if json_obj.get('value'
            ) is not None else None, ignore_if_present=json_obj[
            'ignoreIfPresent'] if json_obj.get('ignoreIfPresent') is not
            None else None)


@dataclass
class SharedStorageEntry:
    """Struct for a single key-value pair in an origin's shared storage."""
    key: str
    value: str

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['key'] = self.key
        json_data['value'] = self.value
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->SharedStorageEntry:
        return cls(key=json_obj['key'], value=json_obj['value'])


@dataclass
class SharedStorageMetadata:
    """Details for an origin's shared storage."""
    creation_time: network.TimeSinceEpoch
    length: int
    remaining_budget: float
    bytes_used: int

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['creationTime'] = self.creation_time.to_json()
        json_data['length'] = self.length
        json_data['remainingBudget'] = self.remaining_budget
        json_data['bytesUsed'] = self.bytes_used
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->SharedStorageMetadata:
        return cls(creation_time=network.TimeSinceEpoch.from_json(json_obj[
            'creationTime']), length=json_obj['length'], remaining_budget=
            json_obj['remainingBudget'], bytes_used=json_obj['bytesUsed'])


@dataclass
class SharedStorageReportingMetadata:
    """Pair of reporting metadata details for a candidate URL for ``selectURL()``."""
    event_type: str
    reporting_url: str

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['eventType'] = self.event_type
        json_data['reportingUrl'] = self.reporting_url
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->SharedStorageReportingMetadata:
        return cls(event_type=json_obj['eventType'], reporting_url=json_obj
            ['reportingUrl'])


@dataclass
class SharedStorageUrlWithMetadata:
    """Bundles a candidate URL with its reporting metadata."""
    url: str
    reporting_metadata: typing.List[SharedStorageReportingMetadata]

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['url'] = self.url
        json_data['reportingMetadata'] = [i.to_json() for i in self.
            reporting_metadata]
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->SharedStorageUrlWithMetadata:
        return cls(url=json_obj['url'], reporting_metadata=[
            SharedStorageReportingMetadata.from_json(i) for i in json_obj[
            'reportingMetadata']])


@dataclass
class StorageBucket:
    storage_key: SerializedStorageKey
    name: typing.Optional[str] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['storageKey'] = self.storage_key.to_json()
        if self.name is not None:
            json_data['name'] = self.name
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->StorageBucket:
        return cls(storage_key=SerializedStorageKey.from_json(json_obj[
            'storageKey']), name=json_obj['name'] if json_obj.get('name')
             is not None else None)


@dataclass
class StorageBucketInfo:
    bucket: StorageBucket
    id_: str
    expiration: network.TimeSinceEpoch
    quota: float
    persistent: bool
    durability: StorageBucketsDurability

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['bucket'] = self.bucket.to_json()
        json_data['id'] = self.id_
        json_data['expiration'] = self.expiration.to_json()
        json_data['quota'] = self.quota
        json_data['persistent'] = self.persistent
        json_data['durability'] = self.durability.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->StorageBucketInfo:
        return cls(bucket=StorageBucket.from_json(json_obj['bucket']), id_=
            json_obj['id'], expiration=network.TimeSinceEpoch.from_json(
            json_obj['expiration']), quota=json_obj['quota'], persistent=
            json_obj['persistent'], durability=StorageBucketsDurability.
            from_json(json_obj['durability']))


@dataclass
class TrustTokens:
    """Pair of issuer origin and number of available (signed, but not used) Trust
Tokens from that issuer."""
    issuer_origin: str
    count: float

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['issuerOrigin'] = self.issuer_origin
        json_data['count'] = self.count
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->TrustTokens:
        return cls(issuer_origin=json_obj['issuerOrigin'], count=json_obj[
            'count'])


@dataclass
class UsageForType:
    """Usage for a storage type."""
    storage_type: StorageType
    usage: float

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        json_data['storageType'] = self.storage_type.to_json()
        json_data['usage'] = self.usage
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->UsageForType:
        return cls(storage_type=StorageType.from_json(json_obj[
            'storageType']), usage=json_obj['usage'])


class AttributionReportingAggregatableResult(enum.Enum):
    SUCCESS = 'success'
    INTERNAL_ERROR = 'internalError'
    NO_CAPACITY_FOR_ATTRIBUTION_DESTINATION = (
        'noCapacityForAttributionDestination')
    NO_MATCHING_SOURCES = 'noMatchingSources'
    EXCESSIVE_ATTRIBUTIONS = 'excessiveAttributions'
    EXCESSIVE_REPORTING_ORIGINS = 'excessiveReportingOrigins'
    NO_HISTOGRAMS = 'noHistograms'
    INSUFFICIENT_BUDGET = 'insufficientBudget'
    INSUFFICIENT_NAMED_BUDGET = 'insufficientNamedBudget'
    NO_MATCHING_SOURCE_FILTER_DATA = 'noMatchingSourceFilterData'
    NOT_REGISTERED = 'notRegistered'
    PROHIBITED_BY_BROWSER_POLICY = 'prohibitedByBrowserPolicy'
    DEDUPLICATED = 'deduplicated'
    REPORT_WINDOW_PASSED = 'reportWindowPassed'
    EXCESSIVE_REPORTS = 'excessiveReports'

    @classmethod
    def from_json(cls, json: str) ->AttributionReportingAggregatableResult:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<AttributionReportingAggregatableResult.{}>'.format(self.value)


class AttributionReportingEventLevelResult(enum.Enum):
    SUCCESS = 'success'
    SUCCESS_DROPPED_LOWER_PRIORITY = 'successDroppedLowerPriority'
    INTERNAL_ERROR = 'internalError'
    NO_CAPACITY_FOR_ATTRIBUTION_DESTINATION = (
        'noCapacityForAttributionDestination')
    NO_MATCHING_SOURCES = 'noMatchingSources'
    DEDUPLICATED = 'deduplicated'
    EXCESSIVE_ATTRIBUTIONS = 'excessiveAttributions'
    PRIORITY_TOO_LOW = 'priorityTooLow'
    NEVER_ATTRIBUTED_SOURCE = 'neverAttributedSource'
    EXCESSIVE_REPORTING_ORIGINS = 'excessiveReportingOrigins'
    NO_MATCHING_SOURCE_FILTER_DATA = 'noMatchingSourceFilterData'
    PROHIBITED_BY_BROWSER_POLICY = 'prohibitedByBrowserPolicy'
    NO_MATCHING_CONFIGURATIONS = 'noMatchingConfigurations'
    EXCESSIVE_REPORTS = 'excessiveReports'
    FALSELY_ATTRIBUTED_SOURCE = 'falselyAttributedSource'
    REPORT_WINDOW_PASSED = 'reportWindowPassed'
    NOT_REGISTERED = 'notRegistered'
    REPORT_WINDOW_NOT_STARTED = 'reportWindowNotStarted'
    NO_MATCHING_TRIGGER_DATA = 'noMatchingTriggerData'

    @classmethod
    def from_json(cls, json: str) ->AttributionReportingEventLevelResult:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<AttributionReportingEventLevelResult.{}>'.format(self.value)


class AttributionReportingSourceRegistrationResult(enum.Enum):
    SUCCESS = 'success'
    INTERNAL_ERROR = 'internalError'
    INSUFFICIENT_SOURCE_CAPACITY = 'insufficientSourceCapacity'
    INSUFFICIENT_UNIQUE_DESTINATION_CAPACITY = (
        'insufficientUniqueDestinationCapacity')
    EXCESSIVE_REPORTING_ORIGINS = 'excessiveReportingOrigins'
    PROHIBITED_BY_BROWSER_POLICY = 'prohibitedByBrowserPolicy'
    SUCCESS_NOISED = 'successNoised'
    DESTINATION_REPORTING_LIMIT_REACHED = 'destinationReportingLimitReached'
    DESTINATION_GLOBAL_LIMIT_REACHED = 'destinationGlobalLimitReached'
    DESTINATION_BOTH_LIMITS_REACHED = 'destinationBothLimitsReached'
    REPORTING_ORIGINS_PER_SITE_LIMIT_REACHED = (
        'reportingOriginsPerSiteLimitReached')
    EXCEEDS_MAX_CHANNEL_CAPACITY = 'exceedsMaxChannelCapacity'
    EXCEEDS_MAX_SCOPES_CHANNEL_CAPACITY = 'exceedsMaxScopesChannelCapacity'
    EXCEEDS_MAX_TRIGGER_STATE_CARDINALITY = 'exceedsMaxTriggerStateCardinality'
    EXCEEDS_MAX_EVENT_STATES_LIMIT = 'exceedsMaxEventStatesLimit'
    DESTINATION_PER_DAY_REPORTING_LIMIT_REACHED = (
        'destinationPerDayReportingLimitReached')

    @classmethod
    def from_json(cls, json: str
        ) ->AttributionReportingSourceRegistrationResult:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<AttributionReportingSourceRegistrationResult.{}>'.format(self
            .value)


class AttributionReportingSourceRegistrationTimeConfig(enum.Enum):
    INCLUDE = 'include'
    EXCLUDE = 'exclude'

    @classmethod
    def from_json(cls, json: str
        ) ->AttributionReportingSourceRegistrationTimeConfig:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<AttributionReportingSourceRegistrationTimeConfig.{}>'.format(
            self.value)


class AttributionReportingSourceType(enum.Enum):
    NAVIGATION = 'navigation'
    EVENT = 'event'

    @classmethod
    def from_json(cls, json: str) ->AttributionReportingSourceType:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<AttributionReportingSourceType.{}>'.format(self.value)


class AttributionReportingTriggerDataMatching(enum.Enum):
    EXACT = 'exact'
    MODULUS = 'modulus'

    @classmethod
    def from_json(cls, json: str) ->AttributionReportingTriggerDataMatching:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<AttributionReportingTriggerDataMatching.{}>'.format(self.value
            )


class InterestGroupAccessType(enum.Enum):
    """Enum of interest group access types."""
    JOIN = 'join'
    LEAVE = 'leave'
    UPDATE = 'update'
    LOADED = 'loaded'
    BID = 'bid'
    WIN = 'win'
    ADDITIONAL_BID = 'additionalBid'
    ADDITIONAL_BID_WIN = 'additionalBidWin'
    TOP_LEVEL_BID = 'topLevelBid'
    TOP_LEVEL_ADDITIONAL_BID = 'topLevelAdditionalBid'
    CLEAR = 'clear'

    @classmethod
    def from_json(cls, json: str) ->InterestGroupAccessType:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<InterestGroupAccessType.{}>'.format(self.value)


class InterestGroupAuctionEventType(enum.Enum):
    """Enum of auction events."""
    STARTED = 'started'
    CONFIG_RESOLVED = 'configResolved'

    @classmethod
    def from_json(cls, json: str) ->InterestGroupAuctionEventType:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<InterestGroupAuctionEventType.{}>'.format(self.value)


class InterestGroupAuctionFetchType(enum.Enum):
    """Enum of network fetches auctions can do."""
    BIDDER_JS = 'bidderJs'
    BIDDER_WASM = 'bidderWasm'
    SELLER_JS = 'sellerJs'
    BIDDER_TRUSTED_SIGNALS = 'bidderTrustedSignals'
    SELLER_TRUSTED_SIGNALS = 'sellerTrustedSignals'

    @classmethod
    def from_json(cls, json: str) ->InterestGroupAuctionFetchType:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<InterestGroupAuctionFetchType.{}>'.format(self.value)


class SharedStorageAccessMethod(enum.Enum):
    """Enum of shared storage access methods."""
    ADD_MODULE = 'addModule'
    CREATE_WORKLET = 'createWorklet'
    SELECT_URL = 'selectURL'
    RUN = 'run'
    BATCH_UPDATE = 'batchUpdate'
    SET_ = 'set'
    APPEND = 'append'
    DELETE = 'delete'
    CLEAR = 'clear'
    GET = 'get'
    KEYS = 'keys'
    VALUES = 'values'
    ENTRIES = 'entries'
    LENGTH = 'length'
    REMAINING_BUDGET = 'remainingBudget'

    @classmethod
    def from_json(cls, json: str) ->SharedStorageAccessMethod:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<SharedStorageAccessMethod.{}>'.format(self.value)


class SharedStorageAccessScope(enum.Enum):
    """Enum of shared storage access scopes."""
    WINDOW = 'window'
    SHARED_STORAGE_WORKLET = 'sharedStorageWorklet'
    PROTECTED_AUDIENCE_WORKLET = 'protectedAudienceWorklet'
    HEADER = 'header'

    @classmethod
    def from_json(cls, json: str) ->SharedStorageAccessScope:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<SharedStorageAccessScope.{}>'.format(self.value)


class StorageBucketsDurability(enum.Enum):
    RELAXED = 'relaxed'
    STRICT = 'strict'

    @classmethod
    def from_json(cls, json: str) ->StorageBucketsDurability:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<StorageBucketsDurability.{}>'.format(self.value)


class StorageType(enum.Enum):
    """Enum of possible storage types."""
    COOKIES = 'cookies'
    FILE_SYSTEMS = 'file_systems'
    INDEXEDDB = 'indexeddb'
    LOCAL_STORAGE = 'local_storage'
    SHADER_CACHE = 'shader_cache'
    WEBSQL = 'websql'
    SERVICE_WORKERS = 'service_workers'
    CACHE_STORAGE = 'cache_storage'
    INTEREST_GROUPS = 'interest_groups'
    SHARED_STORAGE = 'shared_storage'
    STORAGE_BUCKETS = 'storage_buckets'
    ALL_ = 'all'
    OTHER = 'other'

    @classmethod
    def from_json(cls, json: str) ->StorageType:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<StorageType.{}>'.format(self.value)


class InterestGroupAuctionId(str):
    """Protected audience interest group auction identifier.

Represents the CDP type 'Storage.InterestGroupAuctionId'."""

    def to_json(self) ->str:
        return self

    @classmethod
    def from_json(cls, json: str) ->InterestGroupAuctionId:
        return cls(json)

    def __repr__(self) ->str:
        return 'InterestGroupAuctionId({})'.format(super().__repr__())


class SerializedStorageKey(str):
    """Represents the CDP type 'Storage.SerializedStorageKey'."""

    def to_json(self) ->str:
        return self

    @classmethod
    def from_json(cls, json: str) ->SerializedStorageKey:
        return cls(json)

    def __repr__(self) ->str:
        return 'SerializedStorageKey({})'.format(super().__repr__())


class SignedInt64AsBase10(str):
    """Represents the CDP type 'Storage.SignedInt64AsBase10'.

**EXPERIMENTAL**"""

    def to_json(self) ->str:
        return self

    @classmethod
    def from_json(cls, json: str) ->SignedInt64AsBase10:
        return cls(json)

    def __repr__(self) ->str:
        return 'SignedInt64AsBase10({})'.format(super().__repr__())


class UnsignedInt128AsBase16(str):
    """Represents the CDP type 'Storage.UnsignedInt128AsBase16'.

**EXPERIMENTAL**"""

    def to_json(self) ->str:
        return self

    @classmethod
    def from_json(cls, json: str) ->UnsignedInt128AsBase16:
        return cls(json)

    def __repr__(self) ->str:
        return 'UnsignedInt128AsBase16({})'.format(super().__repr__())


class UnsignedInt64AsBase10(str):
    """Represents the CDP type 'Storage.UnsignedInt64AsBase10'.

**EXPERIMENTAL**"""

    def to_json(self) ->str:
        return self

    @classmethod
    def from_json(cls, json: str) ->UnsignedInt64AsBase10:
        return cls(json)

    def __repr__(self) ->str:
        return 'UnsignedInt64AsBase10({})'.format(super().__repr__())


def clear_cookies(browser_context_id: typing.Optional[browser.
    BrowserContextID]=None) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """Clears cookies.

:param ...:

:param browser_context_id: *(Optional)* Browser context to use when called on the browser endpoint."""
    params_dict: T_JSON_DICT = dict()
    if browser_context_id is not None:
        params_dict['browserContextId'] = browser_context_id.to_json()
    cmd_dict = {'method': 'Storage.clearCookies', 'params': params_dict}
    json_result = yield cmd_dict
    return None


def clear_data_for_origin(origin: str, storage_types: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Clears storage for origin.

:param ...:

:param origin: Security origin.

:param storage_types: Comma separated list of StorageType to clear."""
    params_dict: T_JSON_DICT = dict()
    params_dict['origin'] = origin
    params_dict['storageTypes'] = storage_types
    cmd_dict = {'method': 'Storage.clearDataForOrigin', 'params': params_dict}
    json_result = yield cmd_dict
    return None


def clear_data_for_storage_key(storage_key: str, storage_types: str
    ) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """Clears storage for storage key.

:param ...:

:param storage_key: Storage key.

:param storage_types: Comma separated list of StorageType to clear."""
    params_dict: T_JSON_DICT = dict()
    params_dict['storageKey'] = storage_key
    params_dict['storageTypes'] = storage_types
    cmd_dict = {'method': 'Storage.clearDataForStorageKey', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def clear_shared_storage_entries(owner_origin: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Clears all entries for a given origin's shared storage.

**EXPERIMENTAL**

:param ...:

:param owner_origin:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['ownerOrigin'] = owner_origin
    cmd_dict = {'method': 'Storage.clearSharedStorageEntries', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def clear_trust_tokens(issuer_origin: str) ->typing.Generator[T_JSON_DICT,
    T_JSON_DICT, bool]:
    """Removes all Trust Tokens issued by the provided issuerOrigin.
Leaves other stored data, including the issuer's Redemption Records, intact.

**EXPERIMENTAL**

:param ...:

:param issuer_origin:


:returns: True if any tokens were deleted, false otherwise."""
    params_dict: T_JSON_DICT = dict()
    params_dict['issuerOrigin'] = issuer_origin
    cmd_dict = {'method': 'Storage.clearTrustTokens', 'params': params_dict}
    json_result = yield cmd_dict
    return json_result['didDeleteTokens']


def delete_shared_storage_entry(owner_origin: str, key: str
    ) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """Deletes entry for ``key`` (if it exists) for a given origin's shared storage.

**EXPERIMENTAL**

:param ...:

:param owner_origin:

:param key:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['ownerOrigin'] = owner_origin
    params_dict['key'] = key
    cmd_dict = {'method': 'Storage.deleteSharedStorageEntry', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def delete_storage_bucket(bucket: StorageBucket) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Deletes the Storage Bucket with the given storage key and bucket name.

**EXPERIMENTAL**

:param ...:

:param bucket:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['bucket'] = bucket.to_json()
    cmd_dict = {'method': 'Storage.deleteStorageBucket', 'params': params_dict}
    json_result = yield cmd_dict
    return None


def get_affected_urls_for_third_party_cookie_metadata(first_party_url: str,
    third_party_urls: typing.List[str]) ->typing.Generator[T_JSON_DICT,
    T_JSON_DICT, typing.List[str]]:
    """Returns the list of URLs from a page and its embedded resources that match
existing grace period URL pattern rules.
https://developers.google.com/privacy-sandbox/cookies/temporary-exceptions/grace-period

**EXPERIMENTAL**

:param ...:

:param first_party_url: The URL of the page currently being visited.

:param third_party_urls: The list of embedded resource URLs from the page.


:returns: Array of matching URLs. If there is a primary pattern match for the first- party URL, only the first-party URL is returned in the array."""
    params_dict: T_JSON_DICT = dict()
    params_dict['firstPartyUrl'] = first_party_url
    params_dict['thirdPartyUrls'] = [i for i in third_party_urls]
    cmd_dict = {'method':
        'Storage.getAffectedUrlsForThirdPartyCookieMetadata', 'params':
        params_dict}
    json_result = yield cmd_dict
    return [i for i in json_result['matchedUrls']]


def get_cookies(browser_context_id: typing.Optional[browser.
    BrowserContextID]=None) ->typing.Generator[T_JSON_DICT, T_JSON_DICT,
    typing.List[network.Cookie]]:
    """Returns all browser cookies.

:param ...:

:param browser_context_id: *(Optional)* Browser context to use when called on the browser endpoint.


:returns: Array of cookie objects."""
    params_dict: T_JSON_DICT = dict()
    if browser_context_id is not None:
        params_dict['browserContextId'] = browser_context_id.to_json()
    cmd_dict = {'method': 'Storage.getCookies', 'params': params_dict}
    json_result = yield cmd_dict
    return [network.Cookie.from_json(i) for i in json_result['cookies']]


def get_interest_group_details(owner_origin: str, name: str
    ) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, T_JSON_DICT]:
    """Gets details for a named interest group.

**EXPERIMENTAL**

:param ...:

:param owner_origin:

:param name:


:returns: This largely corresponds to: https://wicg.github.io/turtledove/#dictdef-generatebidinterestgroup but has absolute expirationTime instead of relative lifetimeMs and also adds joiningOrigin."""
    params_dict: T_JSON_DICT = dict()
    params_dict['ownerOrigin'] = owner_origin
    params_dict['name'] = name
    cmd_dict = {'method': 'Storage.getInterestGroupDetails', 'params':
        params_dict}
    json_result = yield cmd_dict
    return json_result['details']


def get_related_website_sets() ->typing.Generator[T_JSON_DICT, T_JSON_DICT,
    typing.List[RelatedWebsiteSet]]:
    """Returns the effective Related Website Sets in use by this profile for the browser
session. The effective Related Website Sets will not change during a browser session.

**EXPERIMENTAL**


:returns:"""
    cmd_dict = {'method': 'Storage.getRelatedWebsiteSets'}
    json_result = yield cmd_dict
    return [RelatedWebsiteSet.from_json(i) for i in json_result['sets']]


def get_shared_storage_entries(owner_origin: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, typing.List[SharedStorageEntry]]:
    """Gets the entries in an given origin's shared storage.

**EXPERIMENTAL**

:param ...:

:param owner_origin:


:returns:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['ownerOrigin'] = owner_origin
    cmd_dict = {'method': 'Storage.getSharedStorageEntries', 'params':
        params_dict}
    json_result = yield cmd_dict
    return [SharedStorageEntry.from_json(i) for i in json_result['entries']]


def get_shared_storage_metadata(owner_origin: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, SharedStorageMetadata]:
    """Gets metadata for an origin's shared storage.

**EXPERIMENTAL**

:param ...:

:param owner_origin:


:returns:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['ownerOrigin'] = owner_origin
    cmd_dict = {'method': 'Storage.getSharedStorageMetadata', 'params':
        params_dict}
    json_result = yield cmd_dict
    return SharedStorageMetadata.from_json(json_result['metadata'])


def get_storage_key_for_frame(frame_id: page.FrameId) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, SerializedStorageKey]:
    """Returns a storage key given a frame id.

:param ...:

:param frame_id:


:returns:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['frameId'] = frame_id.to_json()
    cmd_dict = {'method': 'Storage.getStorageKeyForFrame', 'params':
        params_dict}
    json_result = yield cmd_dict
    return SerializedStorageKey.from_json(json_result['storageKey'])


def get_trust_tokens() ->typing.Generator[T_JSON_DICT, T_JSON_DICT, typing.
    List[TrustTokens]]:
    """Returns the number of stored Trust Tokens per issuer for the
current browsing context.

**EXPERIMENTAL**


:returns:"""
    cmd_dict = {'method': 'Storage.getTrustTokens'}
    json_result = yield cmd_dict
    return [TrustTokens.from_json(i) for i in json_result['tokens']]


def get_usage_and_quota(origin: str) ->typing.Generator[T_JSON_DICT,
    T_JSON_DICT, typing.Tuple[float, float, bool, typing.List[UsageForType]]]:
    """Returns usage and quota in bytes.

:param ...:

:param origin: Security origin.


:returns: A tuple with the following items:

    1. **usage** - Storage usage (bytes).
    2. **quota** - Storage quota (bytes).
    3. **overrideActive** - Whether or not the origin has an active storage quota override
    4. **usageBreakdown** - Storage usage per type (bytes)."""
    params_dict: T_JSON_DICT = dict()
    params_dict['origin'] = origin
    cmd_dict = {'method': 'Storage.getUsageAndQuota', 'params': params_dict}
    json_result = yield cmd_dict
    return json_result['usage'], json_result['quota'], json_result[
        'overrideActive'], [UsageForType.from_json(i) for i in json_result[
        'usageBreakdown']]


def override_quota_for_origin(origin: str, quota_size: typing.Optional[
    float]=None) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """Override quota for the specified origin

**EXPERIMENTAL**

:param ...:

:param origin: Security origin.

:param quota_size: *(Optional)* The quota size (in bytes) to override the original quota with. If this is called multiple times, the overridden quota will be equal to the quotaSize provided in the final call. If this is called without specifying a quotaSize, the quota will be reset to the default value for the specified origin. If this is called multiple times with different origins, the override will be maintained for each origin until it is disabled (called without a quotaSize)."""
    params_dict: T_JSON_DICT = dict()
    params_dict['origin'] = origin
    if quota_size is not None:
        params_dict['quotaSize'] = quota_size
    cmd_dict = {'method': 'Storage.overrideQuotaForOrigin', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def reset_shared_storage_budget(owner_origin: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Resets the budget for ``ownerOrigin`` by clearing all budget withdrawals.

**EXPERIMENTAL**

:param ...:

:param owner_origin:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['ownerOrigin'] = owner_origin
    cmd_dict = {'method': 'Storage.resetSharedStorageBudget', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def run_bounce_tracking_mitigations() ->typing.Generator[T_JSON_DICT,
    T_JSON_DICT, typing.List[str]]:
    """Deletes state for sites identified as potential bounce trackers, immediately.

**EXPERIMENTAL**


:returns:"""
    cmd_dict = {'method': 'Storage.runBounceTrackingMitigations'}
    json_result = yield cmd_dict
    return [i for i in json_result['deletedSites']]


def send_pending_attribution_reports() ->typing.Generator[T_JSON_DICT,
    T_JSON_DICT, int]:
    """Sends all pending Attribution Reports immediately, regardless of their
scheduled report time.

**EXPERIMENTAL**


:returns: The number of reports that were sent."""
    cmd_dict = {'method': 'Storage.sendPendingAttributionReports'}
    json_result = yield cmd_dict
    return json_result['numSent']


def set_attribution_reporting_local_testing_mode(enabled: bool
    ) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """https://wicg.github.io/attribution-reporting-api/

**EXPERIMENTAL**

:param ...:

:param enabled: If enabled, noise is suppressed and reports are sent immediately."""
    params_dict: T_JSON_DICT = dict()
    params_dict['enabled'] = enabled
    cmd_dict = {'method': 'Storage.setAttributionReportingLocalTestingMode',
        'params': params_dict}
    json_result = yield cmd_dict
    return None


def set_attribution_reporting_tracking(enable: bool) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Enables/disables issuing of Attribution Reporting events.

**EXPERIMENTAL**

:param ...:

:param enable:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['enable'] = enable
    cmd_dict = {'method': 'Storage.setAttributionReportingTracking',
        'params': params_dict}
    json_result = yield cmd_dict
    return None


def set_cookies(cookies: typing.List[network.CookieParam],
    browser_context_id: typing.Optional[browser.BrowserContextID]=None
    ) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """Sets given cookies.

:param ...:

:param cookies: Cookies to be set.

:param browser_context_id: *(Optional)* Browser context to use when called on the browser endpoint."""
    params_dict: T_JSON_DICT = dict()
    params_dict['cookies'] = [i.to_json() for i in cookies]
    if browser_context_id is not None:
        params_dict['browserContextId'] = browser_context_id.to_json()
    cmd_dict = {'method': 'Storage.setCookies', 'params': params_dict}
    json_result = yield cmd_dict
    return None


def set_interest_group_auction_tracking(enable: bool) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Enables/Disables issuing of interestGroupAuctionEventOccurred and
interestGroupAuctionNetworkRequestCreated.

**EXPERIMENTAL**

:param ...:

:param enable:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['enable'] = enable
    cmd_dict = {'method': 'Storage.setInterestGroupAuctionTracking',
        'params': params_dict}
    json_result = yield cmd_dict
    return None


def set_interest_group_tracking(enable: bool) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Enables/Disables issuing of interestGroupAccessed events.

**EXPERIMENTAL**

:param ...:

:param enable:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['enable'] = enable
    cmd_dict = {'method': 'Storage.setInterestGroupTracking', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def set_protected_audience_k_anonymity(owner: str, name: str, hashes:
    typing.List[str]) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """:param ...:

:param owner:

:param name:

:param hashes:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['owner'] = owner
    params_dict['name'] = name
    params_dict['hashes'] = [i for i in hashes]
    cmd_dict = {'method': 'Storage.setProtectedAudienceKAnonymity',
        'params': params_dict}
    json_result = yield cmd_dict
    return None


def set_shared_storage_entry(owner_origin: str, key: str, value: str,
    ignore_if_present: typing.Optional[bool]=None) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Sets entry with ``key`` and ``value`` for a given origin's shared storage.

**EXPERIMENTAL**

:param ...:

:param owner_origin:

:param key:

:param value:

:param ignore_if_present: *(Optional)* If ``ignoreIfPresent`` is included and true, then only sets the entry if ``key`` doesn't already exist."""
    params_dict: T_JSON_DICT = dict()
    params_dict['ownerOrigin'] = owner_origin
    params_dict['key'] = key
    params_dict['value'] = value
    if ignore_if_present is not None:
        params_dict['ignoreIfPresent'] = ignore_if_present
    cmd_dict = {'method': 'Storage.setSharedStorageEntry', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def set_shared_storage_tracking(enable: bool) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Enables/disables issuing of sharedStorageAccessed events.

**EXPERIMENTAL**

:param ...:

:param enable:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['enable'] = enable
    cmd_dict = {'method': 'Storage.setSharedStorageTracking', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def set_storage_bucket_tracking(storage_key: str, enable: bool
    ) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """Set tracking for a storage key's buckets.

**EXPERIMENTAL**

:param ...:

:param storage_key:

:param enable:"""
    params_dict: T_JSON_DICT = dict()
    params_dict['storageKey'] = storage_key
    params_dict['enable'] = enable
    cmd_dict = {'method': 'Storage.setStorageBucketTracking', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def trac_typeexed_db_for_origin(origin: str) ->typing.Generator[T_JSON_DICT,
    T_JSON_DICT, None]:
    """Registers origin to be notified when an update occurs to its IndexedDB.

:param ...:

:param origin: Security origin."""
    params_dict: T_JSON_DICT = dict()
    params_dict['origin'] = origin
    cmd_dict = {'method': 'Storage.tracTypeexedDBForOrigin', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def trac_typeexed_db_for_storage_key(storage_key: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Registers storage key to be notified when an update occurs to its IndexedDB.

:param ...:

:param storage_key: Storage key."""
    params_dict: T_JSON_DICT = dict()
    params_dict['storageKey'] = storage_key
    cmd_dict = {'method': 'Storage.tracTypeexedDBForStorageKey', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def track_cache_storage_for_origin(origin: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Registers origin to be notified when an update occurs to its cache storage list.

:param ...:

:param origin: Security origin."""
    params_dict: T_JSON_DICT = dict()
    params_dict['origin'] = origin
    cmd_dict = {'method': 'Storage.trackCacheStorageForOrigin', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def track_cache_storage_for_storage_key(storage_key: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Registers storage key to be notified when an update occurs to its cache storage list.

:param ...:

:param storage_key: Storage key."""
    params_dict: T_JSON_DICT = dict()
    params_dict['storageKey'] = storage_key
    cmd_dict = {'method': 'Storage.trackCacheStorageForStorageKey',
        'params': params_dict}
    json_result = yield cmd_dict
    return None


def untrac_typeexed_db_for_origin(origin: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Unregisters origin from receiving notifications for IndexedDB.

:param ...:

:param origin: Security origin."""
    params_dict: T_JSON_DICT = dict()
    params_dict['origin'] = origin
    cmd_dict = {'method': 'Storage.untracTypeexedDBForOrigin', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def untrac_typeexed_db_for_storage_key(storage_key: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Unregisters storage key from receiving notifications for IndexedDB.

:param ...:

:param storage_key: Storage key."""
    params_dict: T_JSON_DICT = dict()
    params_dict['storageKey'] = storage_key
    cmd_dict = {'method': 'Storage.untracTypeexedDBForStorageKey', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def untrack_cache_storage_for_origin(origin: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Unregisters origin from receiving notifications for cache storage.

:param ...:

:param origin: Security origin."""
    params_dict: T_JSON_DICT = dict()
    params_dict['origin'] = origin
    cmd_dict = {'method': 'Storage.untrackCacheStorageForOrigin', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def untrack_cache_storage_for_storage_key(storage_key: str) ->typing.Generator[
    T_JSON_DICT, T_JSON_DICT, None]:
    """Unregisters storage key from receiving notifications for cache storage.

:param ...:

:param storage_key: Storage key."""
    params_dict: T_JSON_DICT = dict()
    params_dict['storageKey'] = storage_key
    cmd_dict = {'method': 'Storage.untrackCacheStorageForStorageKey',
        'params': params_dict}
    json_result = yield cmd_dict
    return None


@event_class('Storage.attributionReportingSourceRegistered')
@dataclass
class AttributionReportingSourceRegistered:
    """**EXPERIMENTAL**"""
    registration: AttributionReportingSourceRegistration
    result: AttributionReportingSourceRegistrationResult

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingSourceRegistered:
        return cls(registration=AttributionReportingSourceRegistration.
            from_json(json_obj['registration']), result=
            AttributionReportingSourceRegistrationResult.from_json(json_obj
            ['result']))


@event_class('Storage.attributionReportingTriggerRegistered')
@dataclass
class AttributionReportingTriggerRegistered:
    """**EXPERIMENTAL**"""
    registration: AttributionReportingTriggerRegistration
    event_level: AttributionReportingEventLevelResult
    aggregatable: AttributionReportingAggregatableResult

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->AttributionReportingTriggerRegistered:
        return cls(registration=AttributionReportingTriggerRegistration.
            from_json(json_obj['registration']), event_level=
            AttributionReportingEventLevelResult.from_json(json_obj[
            'eventLevel']), aggregatable=
            AttributionReportingAggregatableResult.from_json(json_obj[
            'aggregatable']))


@event_class('Storage.cacheStorageContentUpdated')
@dataclass
class CacheStorageContentUpdated:
    """A cache's contents have been modified."""
    origin: str
    storage_key: str
    bucket_id: str
    cache_name: str

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->CacheStorageContentUpdated:
        return cls(origin=json_obj['origin'], storage_key=json_obj[
            'storageKey'], bucket_id=json_obj['bucketId'], cache_name=
            json_obj['cacheName'])


@event_class('Storage.cacheStorageListUpdated')
@dataclass
class CacheStorageListUpdated:
    """A cache has been added/deleted."""
    origin: str
    storage_key: str
    bucket_id: str

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->CacheStorageListUpdated:
        return cls(origin=json_obj['origin'], storage_key=json_obj[
            'storageKey'], bucket_id=json_obj['bucketId'])


@event_class('Storage.indexedDBContentUpdated')
@dataclass
class IndexedDBContentUpdated:
    """The origin's IndexedDB object store has been modified."""
    origin: str
    storage_key: str
    bucket_id: str
    database_name: str
    object_store_name: str

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->IndexedDBContentUpdated:
        return cls(origin=json_obj['origin'], storage_key=json_obj[
            'storageKey'], bucket_id=json_obj['bucketId'], database_name=
            json_obj['databaseName'], object_store_name=json_obj[
            'objectStoreName'])


@event_class('Storage.indexedDBListUpdated')
@dataclass
class IndexedDBListUpdated:
    """The origin's IndexedDB database list has been modified."""
    origin: str
    storage_key: str
    bucket_id: str

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->IndexedDBListUpdated:
        return cls(origin=json_obj['origin'], storage_key=json_obj[
            'storageKey'], bucket_id=json_obj['bucketId'])


@event_class('Storage.interestGroupAccessed')
@dataclass
class InterestGroupAccessed:
    """One of the interest groups was accessed. Note that these events are global
to all targets sharing an interest group store."""
    access_time: network.TimeSinceEpoch
    type_: InterestGroupAccessType
    owner_origin: str
    name: str
    component_seller_origin: typing.Optional[str] = None
    bid: typing.Optional[float] = None
    bid_currency: typing.Optional[str] = None
    unique_auction_id: typing.Optional[InterestGroupAuctionId] = None

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->InterestGroupAccessed:
        return cls(access_time=network.TimeSinceEpoch.from_json(json_obj[
            'accessTime']), type_=InterestGroupAccessType.from_json(
            json_obj['type']), owner_origin=json_obj['ownerOrigin'], name=
            json_obj['name'], component_seller_origin=json_obj[
            'componentSellerOrigin'] if json_obj.get(
            'componentSellerOrigin') is not None else None, bid=json_obj[
            'bid'] if json_obj.get('bid') is not None else None,
            bid_currency=json_obj['bidCurrency'] if json_obj.get(
            'bidCurrency') is not None else None, unique_auction_id=
            InterestGroupAuctionId.from_json(json_obj['uniqueAuctionId']) if
            json_obj.get('uniqueAuctionId') is not None else None)


@event_class('Storage.interestGroupAuctionEventOccurred')
@dataclass
class InterestGroupAuctionEventOccurred:
    """An auction involving interest groups is taking place. These events are
target-specific."""
    event_time: network.TimeSinceEpoch
    type_: InterestGroupAuctionEventType
    unique_auction_id: InterestGroupAuctionId
    parent_auction_id: typing.Optional[InterestGroupAuctionId] = None
    auction_config: typing.Optional[T_JSON_DICT] = None

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->InterestGroupAuctionEventOccurred:
        return cls(event_time=network.TimeSinceEpoch.from_json(json_obj[
            'eventTime']), type_=InterestGroupAuctionEventType.from_json(
            json_obj['type']), unique_auction_id=InterestGroupAuctionId.
            from_json(json_obj['uniqueAuctionId']), parent_auction_id=
            InterestGroupAuctionId.from_json(json_obj['parentAuctionId']) if
            json_obj.get('parentAuctionId') is not None else None,
            auction_config=json_obj['auctionConfig'] if json_obj.get(
            'auctionConfig') is not None else None)


@event_class('Storage.interestGroupAuctionNetworkRequestCreated')
@dataclass
class InterestGroupAuctionNetworkRequestCreated:
    """Specifies which auctions a particular network fetch may be related to, and
in what role. Note that it is not ordered with respect to
Network.requestWillBeSent (but will happen before loadingFinished
loadingFailed)."""
    type_: InterestGroupAuctionFetchType
    request_id: network.RequestId
    auctions: typing.List[InterestGroupAuctionId]

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT
        ) ->InterestGroupAuctionNetworkRequestCreated:
        return cls(type_=InterestGroupAuctionFetchType.from_json(json_obj[
            'type']), request_id=network.RequestId.from_json(json_obj[
            'requestId']), auctions=[InterestGroupAuctionId.from_json(i) for
            i in json_obj['auctions']])


@event_class('Storage.sharedStorageAccessed')
@dataclass
class SharedStorageAccessed:
    """Shared storage was accessed by the associated page.
The following parameters are included in all events."""
    access_time: network.TimeSinceEpoch
    scope: SharedStorageAccessScope
    method: SharedStorageAccessMethod
    main_frame_id: page.FrameId
    owner_origin: str
    owner_site: str
    params: SharedStorageAccessParams

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->SharedStorageAccessed:
        return cls(access_time=network.TimeSinceEpoch.from_json(json_obj[
            'accessTime']), scope=SharedStorageAccessScope.from_json(
            json_obj['scope']), method=SharedStorageAccessMethod.from_json(
            json_obj['method']), main_frame_id=page.FrameId.from_json(
            json_obj['mainFrameId']), owner_origin=json_obj['ownerOrigin'],
            owner_site=json_obj['ownerSite'], params=
            SharedStorageAccessParams.from_json(json_obj['params']))


@event_class('Storage.storageBucketCreatedOrUpdated')
@dataclass
class StorageBucketCreatedOrUpdated:
    bucket_info: StorageBucketInfo

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->StorageBucketCreatedOrUpdated:
        return cls(bucket_info=StorageBucketInfo.from_json(json_obj[
            'bucketInfo']))


@event_class('Storage.storageBucketDeleted')
@dataclass
class StorageBucketDeleted:
    bucket_id: str

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->StorageBucketDeleted:
        return cls(bucket_id=json_obj['bucketId'])
