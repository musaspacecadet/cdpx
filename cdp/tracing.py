# # DO NOT EDIT THIS FILE!
# #
# # This file is generated from the CDP specification using AST. If you need to make
# # changes, edit the generator and regenerate all of the modules.

from __future__ import annotations
"""CDP domain: Tracing"""
import typing
import enum
from dataclasses import dataclass
from .util import T_JSON_DICT, event_class
from . import io
None


class MemoryDumpConfig(dict):
    """Configuration for memory dump. Used only when "memory-infra" category is enabled.

Represents the CDP object type 'Tracing.MemoryDumpConfig'. 
Maps to a dictionary.

**EXPERIMENTAL**"""

    def to_json(self) ->T_JSON_DICT:
        return self

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->MemoryDumpConfig:
        return cls(json_obj)

    def __repr__(self) ->str:
        return 'MemoryDumpConfig({})'.format(super().__repr__())


@dataclass
class TraceConfig:
    record_mode: typing.Optional[str] = None
    trace_buffer_size_in_kb: typing.Optional[float] = None
    enable_sampling: typing.Optional[bool] = None
    enable_systrace: typing.Optional[bool] = None
    enable_argument_filter: typing.Optional[bool] = None
    included_categories: typing.Optional[typing.List[str]] = None
    excluded_categories: typing.Optional[typing.List[str]] = None
    synthetic_delays: typing.Optional[typing.List[str]] = None
    memory_dump_config: typing.Optional[MemoryDumpConfig] = None

    def to_json(self) ->T_JSON_DICT:
        json_data: T_JSON_DICT = dict()
        if self.record_mode is not None:
            json_data['recordMode'] = self.record_mode
        if self.trace_buffer_size_in_kb is not None:
            json_data['traceBufferSizeInKb'] = self.trace_buffer_size_in_kb
        if self.enable_sampling is not None:
            json_data['enableSampling'] = self.enable_sampling
        if self.enable_systrace is not None:
            json_data['enableSystrace'] = self.enable_systrace
        if self.enable_argument_filter is not None:
            json_data['enableArgumentFilter'] = self.enable_argument_filter
        if self.included_categories is not None:
            json_data['includedCategories'] = [i for i in self.
                included_categories]
        if self.excluded_categories is not None:
            json_data['excludedCategories'] = [i for i in self.
                excluded_categories]
        if self.synthetic_delays is not None:
            json_data['syntheticDelays'] = [i for i in self.synthetic_delays]
        if self.memory_dump_config is not None:
            json_data['memoryDumpConfig'] = self.memory_dump_config.to_json()
        return json_data

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->TraceConfig:
        return cls(record_mode=json_obj['recordMode'] if json_obj.get(
            'recordMode') is not None else None, trace_buffer_size_in_kb=
            json_obj['traceBufferSizeInKb'] if json_obj.get(
            'traceBufferSizeInKb') is not None else None, enable_sampling=
            json_obj['enableSampling'] if json_obj.get('enableSampling') is not
            None else None, enable_systrace=json_obj['enableSystrace'] if 
            json_obj.get('enableSystrace') is not None else None,
            enable_argument_filter=json_obj['enableArgumentFilter'] if 
            json_obj.get('enableArgumentFilter') is not None else None,
            included_categories=[i for i in json_obj['includedCategories']] if
            json_obj.get('includedCategories') is not None else None,
            excluded_categories=[i for i in json_obj['excludedCategories']] if
            json_obj.get('excludedCategories') is not None else None,
            synthetic_delays=[i for i in json_obj['syntheticDelays']] if 
            json_obj.get('syntheticDelays') is not None else None,
            memory_dump_config=MemoryDumpConfig.from_json(json_obj[
            'memoryDumpConfig']) if json_obj.get('memoryDumpConfig') is not
            None else None)


class MemoryDumpLevelOfDetail(enum.Enum):
    """Details exposed when memory request explicitly declared.
Keep consistent with memory_dump_request_args.h and
memory_instrumentation.mojom"""
    BACKGROUND = 'background'
    LIGHT = 'light'
    DETAILED = 'detailed'

    @classmethod
    def from_json(cls, json: str) ->MemoryDumpLevelOfDetail:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<MemoryDumpLevelOfDetail.{}>'.format(self.value)


class StreamCompression(enum.Enum):
    """Compression type to use for traces returned via streams."""
    NONE = 'none'
    GZIP = 'gzip'

    @classmethod
    def from_json(cls, json: str) ->StreamCompression:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<StreamCompression.{}>'.format(self.value)


class StreamFormat(enum.Enum):
    """Data format of a trace. Can be either the legacy JSON format or the
protocol buffer format. Note that the JSON format will be deprecated soon."""
    JSON = 'json'
    PROTO = 'proto'

    @classmethod
    def from_json(cls, json: str) ->StreamFormat:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<StreamFormat.{}>'.format(self.value)


class TracingBackend(enum.Enum):
    """Backend type to use for tracing. ``chrome`` uses the Chrome-integrated
tracing service and is supported on all platforms. ``system`` is only
supported on Chrome OS and uses the Perfetto system tracing service.
``auto`` chooses ``system`` when the perfettoConfig provided to Tracing.start
specifies at least one non-Chrome data source; otherwise uses ``chrome``."""
    AUTO = 'auto'
    CHROME = 'chrome'
    SYSTEM = 'system'

    @classmethod
    def from_json(cls, json: str) ->TracingBackend:
        return cls(json)

    def to_json(self) ->str:
        return self.value

    def __repr__(self) ->str:
        return '<TracingBackend.{}>'.format(self.value)


def end() ->typing.Generator[T_JSON_DICT, T_JSON_DICT, None]:
    """Stop trace events collection."""
    cmd_dict = {'method': 'Tracing.end'}
    json_result = yield cmd_dict
    return None


def get_categories() ->typing.Generator[T_JSON_DICT, T_JSON_DICT, typing.
    List[str]]:
    """Gets supported tracing categories.

**EXPERIMENTAL**


:returns: A list of supported tracing categories."""
    cmd_dict = {'method': 'Tracing.getCategories'}
    json_result = yield cmd_dict
    return [i for i in json_result['categories']]


def record_clock_sync_marker(sync_id: str) ->typing.Generator[T_JSON_DICT,
    T_JSON_DICT, None]:
    """Record a clock sync marker in the trace.

**EXPERIMENTAL**

:param ...:

:param sync_id: The ID of this clock sync marker"""
    params_dict: T_JSON_DICT = dict()
    params_dict['syncId'] = sync_id
    cmd_dict = {'method': 'Tracing.recordClockSyncMarker', 'params':
        params_dict}
    json_result = yield cmd_dict
    return None


def request_memory_dump(deterministic: typing.Optional[bool]=None,
    level_of_detail: typing.Optional[MemoryDumpLevelOfDetail]=None
    ) ->typing.Generator[T_JSON_DICT, T_JSON_DICT, typing.Tuple[str, bool]]:
    """Request a global memory dump.

**EXPERIMENTAL**

:param ...:

:param deterministic: *(Optional)* Enables more deterministic results by forcing garbage collection

:param level_of_detail: *(Optional)* Specifies level of details in memory dump. Defaults to "detailed".


:returns: A tuple with the following items:

    1. **dumpGuid** - GUID of the resulting global memory dump.
    2. **success** - True iff the global memory dump succeeded."""
    params_dict: T_JSON_DICT = dict()
    if deterministic is not None:
        params_dict['deterministic'] = deterministic
    if level_of_detail is not None:
        params_dict['levelOfDetail'] = level_of_detail.to_json()
    cmd_dict = {'method': 'Tracing.requestMemoryDump', 'params': params_dict}
    json_result = yield cmd_dict
    return json_result['dumpGuid'], json_result['success']


def start(categories: typing.Optional[str]=None, options: typing.Optional[
    str]=None, buffer_usage_reporting_interval: typing.Optional[float]=None,
    transfer_mode: typing.Optional[str]=None, stream_format: typing.
    Optional[StreamFormat]=None, stream_compression: typing.Optional[
    StreamCompression]=None, trace_config: typing.Optional[TraceConfig]=
    None, perfetto_config: typing.Optional[str]=None, tracing_backend:
    typing.Optional[TracingBackend]=None) ->typing.Generator[T_JSON_DICT,
    T_JSON_DICT, None]:
    """Start trace events collection.

:param ...:

:param categories: **(DEPRECATED)** **(EXPERIMENTAL)** *(Optional)* Category/tag filter

:param options: **(DEPRECATED)** **(EXPERIMENTAL)** *(Optional)* Tracing options

:param buffer_usage_reporting_interval: **(EXPERIMENTAL)** *(Optional)* If set, the agent will issue bufferUsage events at this interval, specified in milliseconds

:param transfer_mode: *(Optional)* Whether to report trace events as series of dataCollected events or to save trace to a stream (defaults to ``ReportEvents``).

:param stream_format: *(Optional)* Trace data format to use. This only applies when using ``ReturnAsStream`` transfer mode (defaults to ``json``).

:param stream_compression: **(EXPERIMENTAL)** *(Optional)* Compression format to use. This only applies when using ``ReturnAsStream`` transfer mode (defaults to ``none``)

:param trace_config: *(Optional)*

:param perfetto_config: **(EXPERIMENTAL)** *(Optional)* Base64-encoded serialized perfetto.protos.TraceConfig protobuf message When specified, the parameters ``categories``, ``options``, ``traceConfig`` are ignored. (Encoded as a base64 string when passed over JSON)

:param tracing_backend: **(EXPERIMENTAL)** *(Optional)* Backend type (defaults to ``auto``)"""
    params_dict: T_JSON_DICT = dict()
    if categories is not None:
        params_dict['categories'] = categories
    if options is not None:
        params_dict['options'] = options
    if buffer_usage_reporting_interval is not None:
        params_dict['bufferUsageReportingInterval'
            ] = buffer_usage_reporting_interval
    if transfer_mode is not None:
        params_dict['transferMode'] = transfer_mode
    if stream_format is not None:
        params_dict['streamFormat'] = stream_format.to_json()
    if stream_compression is not None:
        params_dict['streamCompression'] = stream_compression.to_json()
    if trace_config is not None:
        params_dict['traceConfig'] = trace_config.to_json()
    if perfetto_config is not None:
        params_dict['perfettoConfig'] = perfetto_config
    if tracing_backend is not None:
        params_dict['tracingBackend'] = tracing_backend.to_json()
    cmd_dict = {'method': 'Tracing.start', 'params': params_dict}
    json_result = yield cmd_dict
    return None


@event_class('Tracing.bufferUsage')
@dataclass
class BufferUsage:
    """**EXPERIMENTAL**"""
    percent_full: typing.Optional[float] = None
    event_count: typing.Optional[float] = None
    value: typing.Optional[float] = None

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->BufferUsage:
        return cls(percent_full=json_obj['percentFull'] if json_obj.get(
            'percentFull') is not None else None, event_count=json_obj[
            'eventCount'] if json_obj.get('eventCount') is not None else
            None, value=json_obj['value'] if json_obj.get('value') is not
            None else None)


@event_class('Tracing.dataCollected')
@dataclass
class DataCollected:
    """**EXPERIMENTAL**

Contains a bucket of collected trace events. When tracing is stopped collected events will be
sent as a sequence of dataCollected events followed by tracingComplete event."""
    value: typing.List[T_JSON_DICT]

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->DataCollected:
        return cls(value=[i for i in json_obj['value']])


@event_class('Tracing.tracingComplete')
@dataclass
class TracingComplete:
    """Signals that tracing is stopped and there is no trace buffers pending flush, all data were
delivered via dataCollected events."""
    data_loss_occurred: bool
    stream: typing.Optional[io.StreamHandle] = None
    trace_format: typing.Optional[StreamFormat] = None
    stream_compression: typing.Optional[StreamCompression] = None

    @classmethod
    def from_json(cls, json_obj: T_JSON_DICT) ->TracingComplete:
        return cls(data_loss_occurred=json_obj['dataLossOccurred'], stream=
            io.StreamHandle.from_json(json_obj['stream']) if json_obj.get(
            'stream') is not None else None, trace_format=StreamFormat.
            from_json(json_obj['traceFormat']) if json_obj.get(
            'traceFormat') is not None else None, stream_compression=
            StreamCompression.from_json(json_obj['streamCompression']) if 
            json_obj.get('streamCompression') is not None else None)
