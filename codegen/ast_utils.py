# --- START OF FILE ast_utils.py ---

# ast_utils.py
import ast
import typing
from typing import Any, Dict, Generator, Optional, TypeVar, Protocol, List, Tuple, Literal
from textwrap import dedent
import inflection
import logging

from .models import FieldDefinition, ItemDetails

logger = logging.getLogger(__name__) # Logger for utils

# --- CDPClient Protocol ---

T = TypeVar('T') # For generic return type in send


# Content for the generated util.py
UTIL_PY_CONTENT = '''\
from typing import Any, Dict, Generator, Optional, Type, TypeVar, Callable, Protocol

# Basic type alias for JSON objects
T_JSON_DICT = Dict[str, Any]

T = TypeVar('T')  # For generic return type in send
_event_parsers = dict()

class CDPClient(Protocol):
    """
    Protocol defining the expected interface for a CDP client
    used by the generated API wrappers.
    """

    @property
    def is_connected(self) -> bool:
        """Checks if the connection is currently established and active."""
        ...

    def connect(self) -> None:
        """Establishes the connection to the endpoint."""
        ...

    def disconnect(self) -> None:
        """Disconnects from the endpoint and cleans up resources."""
        ...

    def send(
        self,
        cmd_generator: Generator[Dict[str, Any], Optional[Dict[str, Any]], T],
        _response_timeout: Optional[float] = None
    ) -> T:
        """
        Sends the command generated by cmd_generator to the browser
        and returns the result.

        :param cmd_generator: The generator yielding the command dictionary and
                              expecting the result dictionary.
        :param _response_timeout: Optional timeout in seconds for the operation.
                        If None, the client's default timeout may be used.
        :returns: The result of the command, with the type determined by T.
        """
        ...

    def add_event_listener(self, event_type: Type[T], callback: Callable[[T], None]) -> None:
        """Registers a callback for a specific CDP event type."""
        ...

    def remove_event_listener(self, event_type: Type[T], callback: Callable[[T], None]) -> None:
        """Removes a previously registered callback for a specific CDP event type."""
        ...

    def get_event_name(self, event_cls: Type[T]) -> str:
        """
        Finds the CDP event method name (string) for a given event class type.
        """
        ...

def event_class(event_name: str):
    """Decorator to mark a class as representing a CDP event."""
    def decorator(cls):
        cls._cdp_event_name = event_name
        _event_parsers[event_name] = cls
        return cls
    return decorator

def parse_json_event(json: T_JSON_DICT) -> Any:
    """ Parse a JSON dictionary into a CDP event. """
    return _event_parsers[json['method']].from_json(json['params'])

'''



# --- Basic Utilities ---

def is_builtin(name: str) -> bool:
    try:
        # Use __builtins__ which is available in module scope
        b = __builtins__
        if isinstance(b, dict):
            return name in b
        elif hasattr(b, name):
            return True
        else:
            return False
    except (AttributeError, TypeError): # Handle potential issues accessing __builtins__
         return False


def snake_case(name: str) -> str:
    name = inflection.underscore(name)
    # Check against Python keywords as well
    if is_builtin(name) or name in {'from', 'class', 'return', 'yield', 'async', 'await', 'import', 'def', 'global', 'lambda', 'pass', 'try', 'except'}:
        name += '_'
    return name

def pascal_case(name: str) -> str:
    """Converts snake_case or camelCase to PascalCase."""
    return inflection.camelize(name, uppercase_first_letter=True)

# --- AST Node Creation Helpers ---

def create_import(module: str) -> ast.Import:
    """Creates 'import <module>'"""
    return ast.Import(names=[ast.alias(name=module)])

def create_import_from(module: str, names: typing.List[str], level: int = 0) -> ast.ImportFrom:
    """Creates 'from <.level><module> import <name1>, <name2>'"""
    return ast.ImportFrom(
        module=module,
        names=[ast.alias(name=n) for n in names],
        level=level
    )

def create_import_from_relative(module: str, level: int = 1, alias: Optional[str] = None) -> ast.ImportFrom:
    """Creates 'from .<level> import <module>' or 'from .<level> import <module> as <alias>'"""
    return ast.ImportFrom(module=None, names=[ast.alias(name=module, asname=alias)], level=level)


def create_docstring_node(docstring: typing.Optional[str]) -> typing.List[ast.stmt]:
    """Creates an AST expression node for a docstring if it exists."""
    if not docstring:
        return []
    # Basic backtick escaping for RST in docstrings
    docstring = docstring.replace('`', '``')
    # Use triple double quotes preferred by PEP 257, handle internal ones crudely
    docstring = docstring.replace('"""', '\"\"\"')
    # Dedent the docstring content before wrapping
    dedented_docstring = dedent(docstring).strip() # Also strip leading/trailing whitespace
    if not dedented_docstring:
        return []
    return [ast.Expr(value=ast.Constant(value=dedented_docstring))]


# --- Type Building ---

# Map CDP primitives to Python types/aliases ONCE
primitive_map = {
    'string': 'str', 'integer': 'int', 'number': 'float',
    'boolean': 'bool', 'object': 'T_JSON_DICT', 'any': 'typing.Any'
}


# --- START OF ast_utils.py SNIPPET ---

def _build_type_ast(
    type_ref: Optional[str],
    items: Optional[ItemDetails],
    current_domain_name: str, # Domain being generated (e.g., 'Page', 'BackgroundService')
    context: Literal['base', 'api'],
    # Add alias parameter, only relevant for api context
    primary_domain_module_alias: Optional[str] = None
) -> ast.expr:
    """Internal helper to build the base type AST without Optional wrapper."""
    base_type_ast: ast.expr

    if items: # Array type
        list_type = ast.Attribute(value=ast.Name(id='typing', ctx=ast.Load()), attr='List', ctx=ast.Load())
        # Recursive call for item type
        item_type_ast = build_annotation_ast( # Use public function for recursion
            items.type_ref, None, False, # Item is not optional itself here
            current_domain_name, context, # Pass context down
            primary_domain_module_alias=primary_domain_module_alias # Pass alias down
        )
        base_type_ast = ast.Subscript(value=list_type, slice=item_type_ast, ctx=ast.Load())

    elif type_ref: # Non-array type
        if '.' in type_ref: # Domain reference (e.g., 'Network.RequestId', 'Page.Frame')
            domain, type_name = type_ref.split('.', 1)
            domain_py_name = snake_case(domain)

            if context == 'base':
                if domain == current_domain_name:
                    # Reference within the same domain module (e.g., Page referring to Frame)
                    base_type_ast = ast.Name(id=type_name, ctx=ast.Load())
                else:
                    # Reference to another domain (e.g., Page referring to Network.Cookie)
                    # Assumes 'from . import network' exists via dependency analysis
                    base_type_ast = ast.Attribute(
                        value=ast.Name(id=domain_py_name, ctx=ast.Load()), # network
                        attr=type_name, # Cookie
                        ctx=ast.Load()
                    )
            elif context == 'api':
                 # --- API Context Logic ---
                 if domain == current_domain_name:
                     # Type is from the *same* domain as the API file being generated.
                     # Use the provided alias for the base module import.
                     if not primary_domain_module_alias:
                          # This shouldn't happen if called correctly
                          raise ValueError("primary_domain_module_alias must be provided for API context")
                     base_type_ast = ast.Attribute(
                         value=ast.Name(id=primary_domain_module_alias, ctx=ast.Load()), # e.g., _page_module
                         attr=type_name, # e.g., Frame
                         ctx=ast.Load()
                     )
                 else:
                     # Type is from a *different* domain.
                     # Assumes 'from .. import other_domain' exists. Use direct domain name.
                     base_type_ast = ast.Attribute(
                         value=ast.Name(id=domain_py_name, ctx=ast.Load()), # e.g., network
                         attr=type_name, # e.g., Cookie
                         ctx=ast.Load()
                     )
                 # --- End API Context Logic ---
            else:
                 raise ValueError(f"Invalid context: {context}")

        else: # Primitive type or Any, or unqualified ref within the *current* domain
            py_type_str = primitive_map.get(type_ref.lower())

            if py_type_str == 'typing.Any':
                 base_type_ast = ast.Attribute(value=ast.Name(id='typing', ctx=ast.Load()), attr='Any', ctx=ast.Load())
            elif py_type_str == 'T_JSON_DICT':
                base_type_ast = ast.Name(id='T_JSON_DICT', ctx=ast.Load())
            elif py_type_str: # Other primitives
                base_type_ast = ast.Name(id=py_type_str, ctx=ast.Load())
            else:
                 # Unqualified reference (e.g., 'Frame' within 'Page' domain)
                 if context == 'base':
                     base_type_ast = ast.Name(id=type_ref, ctx=ast.Load())
                 elif context == 'api':
                      # Unqualified ref in API context *must* refer to the primary domain's base type.
                      if not primary_domain_module_alias:
                          raise ValueError("primary_domain_module_alias must be provided for API context")
                      base_type_ast = ast.Attribute(
                          value=ast.Name(id=primary_domain_module_alias, ctx=ast.Load()), # _page_module
                          attr=type_ref, # Frame
                          ctx=ast.Load()
                      )
                 else:
                     raise ValueError(f"Invalid context: {context}")

    else: # No type_ref and no items
         logger.warning("Building annotation AST for field with no type_ref and no items.")
         base_type_ast = ast.Attribute(value=ast.Name(id='typing', ctx=ast.Load()), attr='Any', ctx=ast.Load())

    return base_type_ast

# --- END OF ast_utils.py SNIPPET ---


# --- START OF ast_utils.py SNIPPET ---

def build_annotation_ast(
    type_ref: typing.Optional[str],
    items: typing.Optional[ItemDetails],
    is_optional: bool,
    current_domain_name: str, # Domain being generated (e.g., 'Page')
    context: Literal['base', 'api'],
    is_return_annotation: bool = False,
    # Add alias parameter
    primary_domain_module_alias: Optional[str] = None
) -> ast.expr:
    """
    Builds an AST node for a type annotation, aware of the generation context.
    Handles Optional wrapping and uses alias for primary domain in API context.
    """
    # Pass the alias down to the internal helper
    base_type_ast = _build_type_ast(
        type_ref, items, current_domain_name, context, primary_domain_module_alias
    )

    # Wrap in Optional[...] if needed.
    if is_optional:
        # Avoid Optional[Optional[...]]
        is_already_optional = (
            isinstance(base_type_ast, ast.Subscript) and
            isinstance(base_type_ast.value, ast.Attribute) and
            isinstance(base_type_ast.value.value, ast.Name) and # Check value of Attribute
            base_type_ast.value.value.id == 'typing' and
            base_type_ast.value.attr == 'Optional'
        )
        if not is_already_optional:
            optional_type = ast.Attribute(value=ast.Name(id='typing', ctx=ast.Load()), attr='Optional', ctx=ast.Load())
            return ast.Subscript(value=optional_type, slice=base_type_ast, ctx=ast.Load())
        else:
            return base_type_ast # Already Optional
    else:
        return base_type_ast

# --- END OF ast_utils.py SNIPPET ---

# --- Deserialization ---
def build_from_json_expr(
    field: FieldDefinition,
    json_var_name: str = 'json_obj',
    current_domain_name: str = '' # Domain of the class/function being generated
) -> ast.expr:
    """
    Builds the AST expression to deserialize a field from a JSON dict.
    This is always generated in the 'base' context, so type resolution uses context='base'.
    """
    json_dict_node = ast.Name(id=json_var_name, ctx=ast.Load())
    field_key_node = ast.Constant(value=field.name)
    # Node for raw access like json_obj['field_name'], used after optional check
    raw_dict_access_node = ast.Subscript(
        value=json_dict_node, slice=field_key_node, ctx=ast.Load()
    )

    expr: ast.expr

    # Determine the type expression needed for calling .from_json or list comprehension
    # Crucially, use context='base' as from_json methods exist in base modules.
    if field.items:  # Array type
        item_var = ast.Name(id='i', ctx=ast.Load()) # Variable for list comprehension item
        item_var_store = ast.Name(id='i', ctx=ast.Store())
        list_comp_iterable = raw_dict_access_node # Iterate over json_obj['field_name']

        # Check if items are complex (domain ref) or same-domain non-primitive
        item_is_complex = field.items.type_ref and '.' in field.items.type_ref
        item_is_unqualified_non_primitive = (
            field.items.type_ref and
            '.' not in field.items.type_ref and
            not primitive_map.get(field.items.type_ref.lower())
        )

        if item_is_complex or item_is_unqualified_non_primitive:
            # Need to call item_cls.from_json(i)
            # Resolve the item class name using base context
            item_cls_expr = _build_type_ast(
                field.items.type_ref, None,
                current_domain_name, context='base' # Always base context for from_json
            )
            item_from_json_call = ast.Call(
                func=ast.Attribute(value=item_cls_expr, attr='from_json', ctx=ast.Load()),
                args=[item_var], keywords=[]
            )
            expr = ast.ListComp(
                elt=item_from_json_call,
                generators=[ast.comprehension(target=item_var_store, iter=list_comp_iterable, ifs=[], is_async=0)]
            )
        else: # Array of primitive types or 'any'
            # Just use the items directly
            expr = ast.ListComp(
                elt=item_var,
                generators=[ast.comprehension(target=item_var_store, iter=list_comp_iterable, ifs=[], is_async=0)]
            )

    else: # Not an array
        # Check if field is complex (domain ref) or same-domain non-primitive
        is_complex = field.type_ref and '.' in field.type_ref
        is_unqualified_non_primitive = (
            field.type_ref and
            '.' not in field.type_ref and
            not primitive_map.get(field.type_ref.lower())
        )

        if is_complex or is_unqualified_non_primitive:
            # Need to call cls.from_json(json_obj['field_name'])
            # Resolve the class name using base context
            cls_expr = _build_type_ast(
                 field.type_ref, None, current_domain_name, context='base' # Always base context
            )
            expr = ast.Call(
                func=ast.Attribute(value=cls_expr, attr='from_json', ctx=ast.Load()),
                args=[raw_dict_access_node], keywords=[]
            )
        else: # Primitive type or 'any'
             # Directly access the value
            expr = raw_dict_access_node

    # Handle optional: Use ternary `(expr) if json_obj.get('field_name') is not None else None`
    if field.is_optional:
        # Use .get() for the check itself to avoid KeyError if field is missing
        get_call_for_check = ast.Call(
            func=ast.Attribute(value=json_dict_node, attr='get', ctx=ast.Load()),
            args=[field_key_node], keywords=[]
        )
        # Compare the result of get() to None
        test_expr = ast.Compare(
            left=get_call_for_check, ops=[ast.IsNot()], comparators=[ast.Constant(value=None)]
        )
        # If the test passes, execute the 'expr' built above (which uses raw access)
        expr = ast.IfExp(test=test_expr, body=expr, orelse=ast.Constant(value=None))
    # else: expr is already the correct raw access or from_json call

    return expr


# --- Serialization ---
def build_to_json_assign(
    field: FieldDefinition,
    target_dict_name: str = 'json_data',
    source_expr: Optional[ast.expr] = None, # Provide source directly if not 'self.attr'
    source_obj_name: Optional[str] = 'self' # Use 'self' by default if source_expr not given
) -> typing.List[ast.stmt]:
    """
    Builds AST statement(s) to serialize a field to a JSON dict.
    Handles optional fields by wrapping the assignment in an 'if' block.
    This runs in the 'base' context.
    """

    if source_expr is None:
        if source_obj_name is None:
             raise ValueError("Either source_expr or source_obj_name must be provided")
         # Default source: self.field_name or obj.field_name
        source_node = ast.Attribute(
            value=ast.Name(id=source_obj_name, ctx=ast.Load()),
            attr=snake_case(field.name), # Use Python name
            ctx=ast.Load()
        )
    else:
        # Use the provided expression directly (e.g., a function parameter variable)
        source_node = source_expr

    # Target node: target_dict['cdpFieldName'] = ...
    target_subscript = ast.Subscript(
        value=ast.Name(id=target_dict_name, ctx=ast.Load()),
        slice=ast.Constant(value=field.name), # Use CDP name as key
        ctx=ast.Store()
    )

    value_expr: ast.expr # The expression for the value being assigned

    # Check if the field type requires calling .to_json() or list comprehension
    # This depends on the *Python type* of the source_node value

    # Check item type if it's an array
    item_is_complex = False
    if field.items and field.items.type_ref:
        item_ref = field.items.type_ref
        item_is_complex = ('.' in item_ref) or (not primitive_map.get(item_ref.lower()))

    # Check field type if not an array
    field_is_complex = False
    if not field.items and field.type_ref:
        type_ref = field.type_ref
        field_is_complex = ('.' in type_ref) or (not primitive_map.get(type_ref.lower()))


    if field.items: # Array type
        item_var = ast.Name(id='i', ctx=ast.Load()) # Variable for list comprehension item
        item_var_store = ast.Name(id='i', ctx=ast.Store())
        list_comp_iterable = source_node # Iterate over the source list/array (e.g., self.my_list)

        if item_is_complex: # Array of complex types (requires item.to_json())
            item_to_json_call = ast.Call(
                func=ast.Attribute(value=item_var, attr='to_json', ctx=ast.Load()),
                args=[], keywords=[]
            )
            value_expr = ast.ListComp(
                elt=item_to_json_call,
                generators=[ast.comprehension(target=item_var_store, iter=list_comp_iterable, ifs=[], is_async=0)]
            )
        else: # Array of primitive types or 'any'
            # Just use the items directly
            value_expr = ast.ListComp(
                elt=item_var,
                generators=[ast.comprehension(target=item_var_store, iter=list_comp_iterable, ifs=[], is_async=0)]
            )

    elif field_is_complex: # Single complex type (requires source.to_json())
         value_expr = ast.Call(
             func=ast.Attribute(value=source_node, attr='to_json', ctx=ast.Load()),
             args=[], keywords=[]
         )

    else: # Primitive or Any
         # Assign the value directly
         value_expr = source_node

    # Create the assignment statement: target_dict['cdpName'] = value_expr
    assign_stmt = ast.Assign(targets=[target_subscript], value=value_expr)

    # Handle optional: Wrap assignment in 'if source_node is not None:'
    if field.is_optional:
        # Check the source value/attribute itself
        test_expr = ast.Compare(
            left=source_node,
            ops=[ast.IsNot()],
            comparators=[ast.Constant(value=None)]
        )
        # Return an If statement containing the assignment
        return [ast.If(test=test_expr, body=[assign_stmt], orelse=[])]
    else:
        # Return the assignment statement directly
        return [assign_stmt]


# --- Generator Return Extraction (Helper, maybe not directly used) ---
def extract_generator_return_annotation(gen_annotation: ast.expr) -> Optional[ast.expr]:
    """
    Extracts the third type argument (T) from Generator[X, Y, T].
    Returns the raw AST node for T, or None if extraction fails.
    NOTE: This returns the annotation as defined in the *base* generator.
          The API wrapper needs to rebuild the annotation using context='api'.
    """
    # Ensure gen_annotation is a Subscript node (like Generator[...])
    if not isinstance(gen_annotation, ast.Subscript):
        logger.debug(f"Cannot extract return: Annotation is not a Subscript node: {ast.dump(gen_annotation)}")
        return None

    # Check if the base is typing.Generator
    base_value = gen_annotation.value
    is_generator = (
        isinstance(base_value, ast.Attribute) and
        isinstance(base_value.value, ast.Name) and
        base_value.value.id == 'typing' and
        base_value.attr == 'Generator'
    )

    if not is_generator:
        logger.debug(f"Cannot extract return: Annotation base is not typing.Generator: {ast.dump(base_value)}")
        return None

    # Check if the slice is a Tuple with 3 elements
    slice_value = gen_annotation.slice
    if not isinstance(slice_value, ast.Tuple) or len(slice_value.elts) != 3:
        logger.debug(f"Cannot extract return: Generator slice is not a 3-element Tuple: {ast.dump(slice_value)}")
        return None

    # Return the third element (index 2) - this is the raw node
    return slice_value.elts[2]

# --- END OF FILE ast_utils.py ---